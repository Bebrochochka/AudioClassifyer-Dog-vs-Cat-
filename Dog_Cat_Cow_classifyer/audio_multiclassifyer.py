# -*- coding: utf-8 -*-
"""Audio_Multiclassifyer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YNqw-QWXLx9B20u3mRURF9aKpDUnlDhx
"""





from tensorflow.keras.models import load_model
import librosa
import streamlit as st
import numpy as np
import matplotlib.pyplot as plt

max_len = 88200

model = load_model("multiclass_audio90.h5")

def prepare_data(smaple):
  sound, sr = librosa.load(smaple)

  if len(sound) > max_len:
        sound = sound[:max_len]
  else:
      sound = np.pad(sound, (0, max_len - len(sound)))

  sound = librosa.stft(sound)
  S = librosa.amplitude_to_db(np.abs(sound))
  return S, sr

st.title("Dog vs Cat vs Cow Audio Classifier üê∂üê±üêÑ")
file = st.file_uploader("Upload an audio of DOG or CAT or COW", type=["mp3", "wav"])

if file:
    spectrogram, sr = prepare_data(file)

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–ø–µ–∫—Ç—Ä–æ–≥—Ä–∞–º–º—ã
    fig, ax = plt.subplots()
    img = librosa.display.specshow(spectrogram, sr=22050)
    plt.colorbar(img, ax=ax, format="%+2.f dB")
    st.pyplot(fig)

    X = np.array(spectrogram, np.float32)
    X = X.reshape(1, 1025, 173, 1)
    prediction = model.predict(X)
    classes = ['Cat', 'Cow', 'Dog']  # –ø–æ—Ä—è–¥–æ–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç–æ–º—É, –∫–∞–∫ LabelEncoder –∏—Ö –∫–æ–¥–∏—Ä–æ–≤–∞–ª
    real_pred = classes[np.argmax(prediction)]
    st.write("Predicted class:",(real_pred))
